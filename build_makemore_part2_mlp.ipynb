{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "\t# print(w)\n",
    "\tcontext = [0] * block_size\n",
    "\tfor ch in w + '.':\n",
    "\t\tix = stoi[ch]\n",
    "\t\tX.append(context)\n",
    "\t\tY.append(ix)\n",
    "\t\t# print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "\t\tcontext = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb @ W1 + b1\n",
    "# this won't work because emb needs to be 32 x 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8742, -0.8591,  0.6014,  ...,  0.2661,  0.7489,  0.9776],\n",
       "        [-0.9738,  0.4383, -0.0635,  ...,  0.9833,  1.0000,  0.9997],\n",
       "        [-0.6078, -0.9945,  0.8831,  ..., -0.8877, -1.0000,  0.9745],\n",
       "        ...,\n",
       "        [-0.6249, -0.9984,  0.9604,  ..., -0.8198, -0.7372,  0.9457],\n",
       "        [ 0.1864, -0.9154,  0.8577,  ..., -0.1857, -0.3292,  0.7009],\n",
       "        [-0.9282, -0.8980,  0.8828,  ..., -0.4432,  0.9999,  0.9945]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will work \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emb.view(-1, 6) @ W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -8.9315,  -1.5398,   0.9254,  -6.5288,  -1.1674,   6.0055,  -1.0987,\n",
       "           8.0733,  -6.7984,  -6.1542,   6.0707,  -2.9507,  -0.2381,  -3.0500,\n",
       "          -9.4917,  -0.2935,  -3.9497,  -9.7294,   4.9842,  -1.8987,   5.5143,\n",
       "         -12.9327,  -7.3810,  -1.9113,   9.0722,  12.2058,  -8.3445],\n",
       "        [ -0.8935,   9.9130,   7.9156,  -5.1824,   1.8979,   9.8237,  -6.9917,\n",
       "           4.2284,  -3.6098,  -3.0913,   7.9280,  -3.8731,   0.4485,  -2.6366,\n",
       "          -3.9186,  -8.8504,  -1.4811,   0.5883,  -3.5460,   2.6017,  -2.8674,\n",
       "         -23.3399,  -5.6375,  -6.4986,   2.1219,  14.9639, -12.6961],\n",
       "        [ -4.4338, -12.8605,   9.9954,   9.0294,   4.1604,  -8.6931,   7.1021,\n",
       "           2.7697,   5.6043,  -1.5752,   1.0870,  -0.4906,   1.8511,   4.0801,\n",
       "          -9.3868,   7.3674,  -9.4683,  -6.3988,   2.4718,  -2.0402,  -1.0523,\n",
       "           6.1155,   0.8294,  -3.8077,  -4.6265,  -7.0551,  -3.7027],\n",
       "        [ 12.2795,  -5.9020,   4.0471,  -1.3756,   5.9885,  -1.7657,   0.8638,\n",
       "          -2.6149,   0.1898,  -1.1069, -10.2167,  10.9123,  13.1422,  -1.9455,\n",
       "          -0.3806,  11.7360,  -7.7575,  -8.7893,   8.9955,   6.6375,   5.3885,\n",
       "         -10.9821,   5.2322,  -9.1685,   2.8655,  -7.0808,  -0.6508],\n",
       "        [ -1.8310,  14.5511, -16.1227,  -5.4437,  -6.7682,  -1.7693,  -8.6855,\n",
       "          11.3746,  -9.4255, -16.7826,  -0.5815,  -3.1871,  -9.1979,  -9.4966,\n",
       "           5.9890,  -3.3656,  14.2854,  -3.2459,   4.4622,  -5.8575,   4.7879,\n",
       "         -19.9012, -18.1653,   0.7216,  -1.7765,  14.6523,   6.2748],\n",
       "        [ -8.9315,  -1.5398,   0.9254,  -6.5288,  -1.1674,   6.0055,  -1.0987,\n",
       "           8.0733,  -6.7984,  -6.1542,   6.0707,  -2.9507,  -0.2381,  -3.0500,\n",
       "          -9.4917,  -0.2935,  -3.9497,  -9.7294,   4.9842,  -1.8987,   5.5143,\n",
       "         -12.9327,  -7.3810,  -1.9113,   9.0722,  12.2058,  -8.3445],\n",
       "        [ -5.3757,  -8.3162,  -0.8257,  -8.8789,   1.6417,  -1.6296,   1.1606,\n",
       "          11.6714,  -2.9331,  -4.5290,   6.1911,  -4.5970,  -3.3293,  -6.2474,\n",
       "          -6.7110,   6.0830,  -4.1346, -12.0763,  10.4942,  -9.8299,  11.3704,\n",
       "          -7.0395,  -2.0299,   0.7744,   7.9831,   4.4743,  -0.5110],\n",
       "        [  2.9442,  -1.1425,   9.6972,   2.7202,  10.7212,  -2.2206,  -2.9946,\n",
       "          -1.7216,  -1.9491, -12.9381, -10.3674,   4.1090,  -3.1618,  -2.6196,\n",
       "          -6.0581,  14.9335,  -8.2579, -12.3908,  19.3181,  -7.4245,  17.0531,\n",
       "          12.1099,   6.9823,   5.3629,  -5.5406, -17.9089,  13.7992],\n",
       "        [  3.3612,  18.2290, -15.3728, -14.7977,   0.5181,  -4.1532, -11.7471,\n",
       "          15.2389, -11.0248,  -5.1626,   6.0858,  -5.2312, -11.8796,  -5.1022,\n",
       "          10.3009,  -0.9079,   1.5127, -12.8072,  16.9610,  -7.9036,   2.9310,\n",
       "          -4.2350,   3.0289,   5.3837,   4.7536,  15.4018,   9.1417],\n",
       "        [ -9.5761,  20.8433, -10.1899,  -9.2610,  -5.7816,  -6.1040,   1.5559,\n",
       "           6.7366,  -6.8142, -16.6463,  14.9625, -11.8494, -17.4458, -17.2285,\n",
       "           3.3620,  -5.5885,   9.9031, -10.1837,  14.9973, -18.2200,   3.0359,\n",
       "          -2.4799,  -7.6204,  -7.5273,  -1.8064,  14.6790,  16.6915],\n",
       "        [ -6.2863,   6.7464,  -4.6861, -15.3853,   2.4845,   0.4946,  -2.0157,\n",
       "           9.1240,  -9.2633,  -9.8678,   9.7242,  -6.8454,  -8.5136,  -7.2464,\n",
       "          -3.1275,   5.1008,  -3.3522, -14.0025,  17.1090, -14.7597,   7.7413,\n",
       "          -1.7058,  -3.1073,   1.0800,   3.8453,  13.0355,  10.5499],\n",
       "        [ -5.5030,  13.0702,  -7.5991, -11.9034,   0.4408,   5.2082,  -5.7916,\n",
       "          10.0937, -12.6896,  -6.4697,   5.9567, -11.0531,  -4.7122,  -6.1819,\n",
       "           1.3273,  -2.5068,  -3.4384, -12.9596,   8.3401,  -6.2100,   3.6208,\n",
       "         -12.3679,  -8.5091,  -0.8113,   8.5541,  19.5438,  -2.9839],\n",
       "        [ -8.9315,  -1.5398,   0.9254,  -6.5288,  -1.1674,   6.0055,  -1.0987,\n",
       "           8.0733,  -6.7984,  -6.1542,   6.0707,  -2.9507,  -0.2381,  -3.0500,\n",
       "          -9.4917,  -0.2935,  -3.9497,  -9.7294,   4.9842,  -1.8987,   5.5143,\n",
       "         -12.9327,  -7.3810,  -1.9113,   9.0722,  12.2058,  -8.3445],\n",
       "        [ -8.8846,   0.3783,   1.6917,  -4.2596,   0.3801,   6.1403,  -0.7672,\n",
       "           6.7520,  -6.8004,  -5.8336,   5.8505,  -2.0397,   1.0266,  -2.9282,\n",
       "          -9.5611,  -1.3540,  -4.0671,  -7.7648,   3.3987,  -0.8582,   2.7625,\n",
       "         -13.8500,  -7.0620,  -1.9647,   6.9279,  12.5585, -10.6016],\n",
       "        [ -8.8983,  -7.7942,  -0.7663,  -4.5462,  -1.2578,  -0.7905,   2.9850,\n",
       "          12.4131,  -1.5692,  -5.7940,   5.3683,  -3.5417,  -0.5366,  -3.8855,\n",
       "          -9.4500,   2.3962,  -3.9409,  -8.1495,   4.9083,  -7.2279,  11.5297,\n",
       "         -10.0553,  -6.2349,  -1.0335,   6.9456,   5.6482,  -5.6853],\n",
       "        [ -5.9509,   3.9821,  -2.6133,  -9.2415,   0.2134,   9.6084,  -6.6289,\n",
       "           3.4180,  -9.9816,  -3.6491,   3.2460,  -2.6113,   0.8688,  -4.8425,\n",
       "          -5.7447,  -1.1558,  -3.5537, -11.2286,   6.2550,   1.5329,   3.4248,\n",
       "         -18.8752,  -5.9050,  -2.2638,   9.5155,  14.6546,  -7.5382],\n",
       "        [ -8.9315,  -1.5398,   0.9254,  -6.5288,  -1.1674,   6.0055,  -1.0987,\n",
       "           8.0733,  -6.7984,  -6.1542,   6.0707,  -2.9507,  -0.2381,  -3.0500,\n",
       "          -9.4917,  -0.2935,  -3.9497,  -9.7294,   4.9842,  -1.8987,   5.5143,\n",
       "         -12.9327,  -7.3810,  -1.9113,   9.0722,  12.2058,  -8.3445],\n",
       "        [ -3.5296,  -8.0698,   0.8457,  -7.5379,   4.8357,  -2.9658,   2.5897,\n",
       "          10.4029,  -2.0030,  -3.9814,   4.2838,  -3.9767,  -2.1306,  -5.8569,\n",
       "          -6.4676,   8.0093,  -4.7445, -12.0635,  11.8473, -10.3100,  11.2937,\n",
       "          -5.0889,  -0.0996,   1.3816,   5.5257,   1.9819,   0.5587],\n",
       "        [ -2.7767,   6.6295,  -5.8098, -12.0025,   3.9331,   4.4764,  -9.5008,\n",
       "           5.3936,  -8.0786,  -3.3508,   3.7094,  -0.9688,  -8.4664,  -8.2349,\n",
       "          -0.8419,   5.2463,  -0.6920, -16.8815,  17.0366,  -5.3576,   7.1806,\n",
       "         -10.4175,   0.9862,  -0.1938,   6.9298,   9.7908,   3.3626],\n",
       "        [ -5.0838,  16.3594,  -9.6988, -10.5855,  -1.8953,  -0.7839,  -3.3666,\n",
       "          12.1732, -11.4565, -13.5314,   8.8444, -13.5946,  -8.6853,  -7.6861,\n",
       "           1.8543,  -3.6451,  -0.4150, -11.3903,   9.1828, -11.0744,   3.6482,\n",
       "          -9.3327, -11.8239,  -1.7255,   4.2640,  20.0180,   0.4416],\n",
       "        [ -8.2780,  12.3171,   3.1547,  10.4557,   8.8050,  -5.3626,   8.0350,\n",
       "           0.1038,  -0.9119,  -7.0966,   6.9369,  -7.9006,   2.7485,  -4.5917,\n",
       "           2.0022,  -8.8971,   2.1478,   1.9242,  -2.6937,  -6.5848,  -8.2446,\n",
       "          -6.4228,  -7.5550,  -0.5708,  -7.0692,  10.7783, -10.4887],\n",
       "        [ -6.7629,  -1.7182,  -1.7091,   4.8561,  -7.4294,   4.1310,  -0.3720,\n",
       "           8.9069,   8.3290,  -3.2256,   4.0560,   3.2084,  -1.7312,   4.7379,\n",
       "          -0.7260,  -5.9342,   8.4865,   7.3780,  -7.5704,   6.0363,  -5.4939,\n",
       "         -21.1876,  -6.5207,   0.7388,  -3.2418,   5.2372, -15.7871],\n",
       "        [ -3.8446, -19.9131,   6.1383,   5.2171,   5.6383,  -2.3486,   8.3769,\n",
       "          -1.7239,  -1.8566,  -2.1847,  -7.1817,  -2.5595,   0.2880,   1.9249,\n",
       "         -11.6729,  13.2148,  -4.5372,  -7.8579,   5.1997,  -2.0256,   5.7087,\n",
       "           9.5389,  11.2696,   0.6705,  -4.8745, -21.0153,   9.6213],\n",
       "        [ 14.4486,   5.5435,   1.7285,  -3.1731,   8.0309,  -1.4797,  -9.9495,\n",
       "          -5.2941,  -7.1655, -13.0783,  -9.4995,  12.3412,  -1.8935,  -7.0586,\n",
       "           1.8172,  11.1786,  -8.0568, -13.4271,  15.2899,   2.2248,  15.2228,\n",
       "           1.7004,   9.3800,   0.3261,  -1.8303,  -6.8062,  10.6287],\n",
       "        [  2.1480,  27.1938, -11.2399, -17.0880,  -3.7197, -15.3580, -11.1694,\n",
       "          16.9697,  -9.3454,  -7.2186,   8.2856, -11.0441, -13.1413, -13.2052,\n",
       "          14.1771,  -5.5608,  10.0099,  -8.7985,  19.8639, -15.7897,   8.5029,\n",
       "          -4.1972,  -0.0376,  -4.1384,   3.0942,  14.4835,  10.5567],\n",
       "        [ -8.9315,  -1.5398,   0.9254,  -6.5288,  -1.1674,   6.0055,  -1.0987,\n",
       "           8.0733,  -6.7984,  -6.1542,   6.0707,  -2.9507,  -0.2381,  -3.0500,\n",
       "          -9.4917,  -0.2935,  -3.9497,  -9.7294,   4.9842,  -1.8987,   5.5143,\n",
       "         -12.9327,  -7.3810,  -1.9113,   9.0722,  12.2058,  -8.3445],\n",
       "        [ -4.2128,  -7.8554,   0.7501,  -6.4183,   4.7848,  -2.0606,   3.1475,\n",
       "           9.7969,  -2.3147,  -3.6620,   4.7190,  -3.6320,  -0.9451,  -5.0138,\n",
       "          -7.1341,   7.2282,  -5.2006, -12.1159,  10.1062,  -8.5903,  10.0291,\n",
       "          -6.4594,  -0.8942,   0.5279,   5.8315,   3.6494,  -2.5000],\n",
       "        [ -4.5736,   3.0474,  -5.0380, -13.7506,   0.8537,   4.4182,  -9.3870,\n",
       "           8.8139,  -7.2988,  -5.2219,   5.8517,  -1.2521,  -8.9973,  -8.1047,\n",
       "          -2.3636,   5.5072,  -0.2486, -15.1771,  16.9340,  -7.7515,   9.1646,\n",
       "          -9.5999,  -0.4446,   2.3178,   8.1583,   9.6580,   4.4953],\n",
       "        [ -1.3570,  12.9858,  -9.7015,  -9.5800,   3.7838,  -1.2119,  -2.6937,\n",
       "           8.0618, -10.3764,  -6.0612,   7.5413, -11.7103,  -6.6798,  -7.8267,\n",
       "           1.5411,  -1.2513,  -3.3459, -14.8758,  12.7470, -11.2533,   1.7216,\n",
       "          -6.2681,  -4.9238,  -0.0678,   7.2922,  16.7147,  -1.5101],\n",
       "        [  0.9187,   1.2084,  -0.8566,   0.9024,   7.4478, -17.4524,   6.9317,\n",
       "           6.7510,  -0.5437,  -9.3101,  -1.8850,   0.5432,  -1.2329,   3.0327,\n",
       "           1.8761,  11.3770,  -3.1183,  -6.6078,   7.1452, -14.1271,   1.9834,\n",
       "          10.7263,  -2.1967,   1.2388,  -9.6698,   0.6080,  -1.8136],\n",
       "        [ -3.6350,   0.6236,  -8.4121,  -5.6732,  -3.6666,  -2.1964,  -9.5813,\n",
       "           9.3440,  -3.7797, -14.6227,  -5.4085,   5.0726,  -2.3291,  -6.3250,\n",
       "           0.4140,   9.0020,   5.8990,  -8.7816,  17.9366,  -8.3646,  14.0360,\n",
       "          -6.6988,  -4.5641,   4.3542,  -0.7056,   3.6049,  13.1571],\n",
       "        [  5.6369,  16.4843, -10.9784, -12.4744,  -3.6813,   3.7353, -12.2813,\n",
       "           9.9497, -12.6739,  -8.7767,   8.7934, -10.6891,  -8.0442, -11.1158,\n",
       "           5.7247,  -8.2467,   8.1684, -10.2580,  11.6966,  -6.5296,   0.9280,\n",
       "         -17.9341,  -9.3245,   0.2109,   7.2404,  15.7396,   3.1110]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5913)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- now made respectable -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "X.shape, Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2))\n",
    "\n",
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)\n",
    "\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.57481050491333\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "\n",
    "\t# minibatch construct\n",
    "\tix = torch.randint(0, X.shape[0], (32, ))\n",
    "\n",
    "\t# forward pass\n",
    "\temb = C[X[ix]] # (32, 3, 2)\n",
    "\th = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "\tlogits = h @ W2 + b2 # (32, 27)\n",
    "\tloss = F.cross_entropy(logits, Y[ix])\n",
    "\n",
    "\t# backward pass\n",
    "\tfor p in parameters:\n",
    "\t\t\tp.grad = None\n",
    "\tloss.backward()\n",
    "\n",
    "\t# update\n",
    "\tfor p in parameters:\n",
    "\t\t\tp.data += -0.1 * p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6629, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
